from __future__ import annotations
from typing import Optional, Literal, Any
import numpy as np
import pymc as pm
import pytensor.tensor as pt
import arviz as az

LinkType = Literal["logit", "cloglog", "loglog", "plogit", "splogit",
                    "lpe", "grg", "skewprobit", "rh", "glogit"]
SamplerType = Literal["nuts", "hmc", "gibbs", "slice", "mh", "metropolis"]


def _sigmoid(x: pt.TensorVariable) -> pt.TensorVariable:
    return 1 / (1 + pt.exp(-x))


def inv_logit_pt(eta: pt.TensorVariable) -> pt.TensorVariable:
    return _sigmoid(eta)


def inv_cloglog_pt(eta: pt.TensorVariable) -> pt.TensorVariable:
    return 1.0 - pt.exp(-pt.exp(eta))


def inv_loglog_pt(eta: pt.TensorVariable) -> pt.TensorVariable:
    return pt.exp(-pt.exp(-eta))


def inv_plogit_pt(eta: pt.TensorVariable, r: pt.TensorVariable) -> pt.TensorVariable:
    return pt.switch(
        pt.le(r, 1.0),
        _sigmoid(eta / r) ** r,
        1.0 - _sigmoid(-r * eta) ** (1.0 / r),
    )


def inv_splogit_pt(eta: pt.TensorVariable, r: pt.TensorVariable) -> pt.TensorVariable:
    return inv_plogit_pt(eta, r)


def inv_lpe_pt(eta: pt.TensorVariable, xi: pt.TensorVariable) -> pt.TensorVariable:
    logit_p = _sigmoid(eta)
    return pt.power(logit_p, xi)


def inv_grg_pt(eta: pt.TensorVariable) -> pt.TensorVariable:
    gumbel_max = pt.exp(-pt.exp(-eta))
    reverse_gumbel = 1.0 - pt.exp(-pt.exp(eta))
    return 0.5 * (gumbel_max + reverse_gumbel)


def inv_skewprobit_pt(eta: pt.TensorVariable, lambda_skew: pt.TensorVariable) -> pt.TensorVariable:
    phi_eta = 0.5 * pt.erfc(-eta / pt.sqrt(2.0))
    phi_lambda_eta = 0.5 * pt.erfc(-lambda_skew * eta / pt.sqrt(2.0))
    return 2.0 * phi_eta * phi_lambda_eta


def inv_rh_pt(eta: pt.TensorVariable, hermite_coeffs: pt.TensorVariable) -> pt.TensorVariable:
    correction = hermite_coeffs[2] * (eta**2 - 1.0)
    eta_corrected = eta + correction
    return 0.5 * pt.erfc(-eta_corrected / pt.sqrt(2.0))


def _h_alpha_pt(eta: pt.TensorVariable, alpha: pt.TensorVariable, positive: bool = True) -> pt.TensorVariable:
    eps = 1e-10

    if positive:
        h_pos = (pt.exp(alpha * eta) - 1.0) / (alpha + eps)
        h_zero = eta
        h_neg = -pt.log(pt.clip(1.0 - alpha * eta, eps, 1e10)) / (alpha - eps)

        result = pt.switch(
            pt.gt(alpha, eps),
            h_pos,
            pt.switch(
                pt.lt(alpha, -eps),
                h_neg,
                h_zero
            )
        )
    else:
        eta_abs = pt.abs(eta)
        h_pos = -(pt.exp(alpha * eta_abs) - 1.0) / (alpha + eps)
        h_zero = eta
        h_neg = pt.log(pt.clip(1.0 - alpha * eta_abs, eps, 1e10)) / (alpha - eps)

        result = pt.switch(
            pt.gt(alpha, eps),
            h_pos,
            pt.switch(
                pt.lt(alpha, -eps),
                h_neg,
                h_zero
            )
        )

    return result


def inv_glogit_pt(eta: pt.TensorVariable, alpha1: pt.TensorVariable, alpha2: pt.TensorVariable) -> pt.TensorVariable:
    h_eta_positive = _h_alpha_pt(eta, alpha1, positive=True)
    h_eta_negative = _h_alpha_pt(eta, alpha2, positive=False)
    h_eta = pt.switch(pt.gt(eta, 0.0), h_eta_positive, h_eta_negative)
    return _sigmoid(h_eta)


def get_inverse_link_pt(link: str, r: Optional[pt.TensorVariable] = None,
                        xi: Optional[pt.TensorVariable] = None,
                        lambda_skew: Optional[pt.TensorVariable] = None,
                        hermite_coeffs: Optional[pt.TensorVariable] = None,
                        alpha1: Optional[pt.TensorVariable] = None,
                        alpha2: Optional[pt.TensorVariable] = None):
    link_lower = link.lower()

    if link_lower == "logit":
        return lambda eta: inv_logit_pt(eta)
    elif link_lower == "cloglog":
        return lambda eta: inv_cloglog_pt(eta)
    elif link_lower == "loglog":
        return lambda eta: inv_loglog_pt(eta)
    elif link_lower == "plogit":
        if r is None:
            raise ValueError("plogit requires r parameter")
        return lambda eta: inv_plogit_pt(eta, r)
    elif link_lower == "splogit":
        if r is None:
            raise ValueError("splogit requires r parameter")
        return lambda eta: inv_splogit_pt(eta, r)
    elif link_lower == "lpe":
        if xi is None:
            raise ValueError("lpe requires xi parameter")
        return lambda eta: inv_lpe_pt(eta, xi)
    elif link_lower == "grg":
        return lambda eta: inv_grg_pt(eta)
    elif link_lower == "skewprobit":
        if lambda_skew is None:
            raise ValueError("skewprobit requires lambda_skew parameter")
        return lambda eta: inv_skewprobit_pt(eta, lambda_skew)
    elif link_lower == "rh":
        if hermite_coeffs is None:
            raise ValueError("rh requires hermite_coeffs parameter")
        return lambda eta: inv_rh_pt(eta, hermite_coeffs)
    elif link_lower == "glogit":
        if alpha1 is None or alpha2 is None:
            raise ValueError("glogit requires alpha1 and alpha2 parameters")
        return lambda eta: inv_glogit_pt(eta, alpha1, alpha2)
    else:
        raise ValueError(f"Unknown link '{link}'. Choose from: logit, cloglog, loglog, plogit, splogit, lpe, grg, skewprobit, rh, glogit")


def build_irt_model(
    y: np.ndarray,
    link: LinkType,
    mu_loga: float = np.log(0.5),
    tau_loga: float = 25.0,
    lower_a: float = 0.25,
    upper_a: float = 0.75,
    c_b1: float = 2.0,          
    c_b2: float = 2.0,
    mu_b_ratio: float = 1.0,    
    fix_mu_b_zero: bool = False,
    mu_theta: float = 0.0,
    tau_theta: float = 1.0,
    fix_mu_mean: bool = True,
    fix_mu_sd: bool = True,
    mu_log_r: float = 0.0,
    tau_log_r: float = 1.0,
    c_epsilon1: float = 100.0,  
    c_epsilon2: float = 1.0,
    infer_p_epsilon: bool = True,
    fixed_p_epsilon: Optional[float] = None,
    alpha_p_epsilon: float = 2.0,  
    beta_p_epsilon: float = 6.0,  
    marginalize_skew: bool = True,  
    alpha_xi: float = 2.0,      
    beta_xi: float = 1.0,
    mu_lambda: float = 0.0,    
    tau_lambda: float = 1.0,
    hermite_order: int = 2,      
    mu_alpha1: float = 0.0,     
    tau_alpha1: float = 1.0,
    mu_alpha2: float = 0.0,      
    tau_alpha2: float = 1.0,
) -> tuple[pm.Model, dict]:
    assert y.ndim == 2, "y must be a 2D array"
    assert y.dtype in (np.int8, np.int16, np.int32, np.int64), "y must contain integers"
    
    N, I = y.shape
    coords = {"person": np.arange(N), "item": np.arange(I)}
    
    with pm.Model(coords=coords) as model:
        loga = pm.TruncatedNormal(
            "loga",
            mu=mu_loga,
            sigma=pt.sqrt(1.0 / tau_loga),
            lower=np.log(lower_a + 1e-6),
            upper=np.log(upper_a - 1e-6),
            dims="item",
        )
        a = pm.Deterministic("a", pt.exp(loga), dims="item")
        
        tau_b = pm.Gamma("tau_b", alpha=c_b1, beta=c_b2)
        
        if fix_mu_b_zero:
            mu_b = pm.Deterministic("mu_b", pt.as_tensor_variable(0.0))
        else:
            mu_b = pm.Normal("mu_b", mu=0.0, sigma=pt.sqrt(mu_b_ratio / tau_b))
        
        b = pm.Normal("b", mu=mu_b, sigma=pt.sqrt(1.0 / tau_b), dims="item")
        
        if fix_mu_mean or fix_mu_sd:
            mu_raw = pm.Normal(
                "mu_raw",
                mu=mu_theta,
                sigma=pt.sqrt(1.0 / tau_theta),
                dims="person"
            )
            mu_centered = mu_raw - pt.mean(mu_raw)
            
            if fix_mu_sd:
                mu_scale = pt.sqrt(pt.var(mu_centered) + 1e-8)
                mu_id = mu_centered / mu_scale
            else:
                mu_id = mu_centered
            
            mu = pm.Deterministic("mu", mu_id, dims="person")
        else:
            mu = pm.Normal(
                "mu",
                mu=mu_theta,
                sigma=pt.sqrt(1.0 / tau_theta),
                dims="person"
            )
        
        uses_r = link.lower() in {"plogit", "splogit"}
        if uses_r:
            log_r = pm.Normal("log_r", mu=mu_log_r, sigma=pt.sqrt(1.0 / tau_log_r))
            r_rv = pm.Deterministic("r", pt.exp(log_r))
        else:
            r_rv = None

        xi_rv = None
        lambda_skew_rv = None
        hermite_coeffs_rv = None
        alpha1_rv = None
        alpha2_rv = None

        if link.lower() == "lpe":
            xi_rv = pm.Gamma("xi", alpha=alpha_xi, beta=beta_xi)

        elif link.lower() == "skewprobit":
            lambda_skew_rv = pm.Normal("lambda_skew", mu=mu_lambda, sigma=pt.sqrt(1.0 / tau_lambda))

        elif link.lower() == "rh":
            hermite_coeffs_list = [pt.as_tensor_variable(0.0), pt.as_tensor_variable(0.0)]
            for k in range(2, hermite_order + 1):
                c_k = pm.Normal(f"hermite_c{k}", mu=0.0, sigma=0.1)
                hermite_coeffs_list.append(c_k)
            hermite_coeffs_rv = pt.stack(hermite_coeffs_list)

        elif link.lower() == "glogit":
            alpha1_rv = pm.Normal("alpha1", mu=mu_alpha1, sigma=pt.sqrt(1.0 / tau_alpha1))
            alpha2_rv = pm.Normal("alpha2", mu=mu_alpha2, sigma=pt.sqrt(1.0 / tau_alpha2))

        eta_base = (mu[:, None] - b[None, :]) * a[None, :]

        if link.lower() == "splogit":
            tau_epsilon = pm.Gamma("tau_epsilon", alpha=c_epsilon1, beta=c_epsilon2)

            if infer_p_epsilon:
                p_epsilon = pm.Beta("p_epsilon", alpha=alpha_p_epsilon, beta=beta_p_epsilon)
            else:
                if fixed_p_epsilon is None:
                    raise ValueError("fixed_p_epsilon must be provided when infer_p_epsilon=False")
                p_epsilon = pm.Deterministic("p_epsilon", pt.as_tensor_variable(fixed_p_epsilon))

            if marginalize_skew:

                inv_link = get_inverse_link_pt(link, r=r_rv)
                sigma_eps = pt.sqrt(1.0 / tau_epsilon)

                p0 = inv_link(eta_base)
                loglik0 = y * pt.log(pt.clip(p0, 1e-10, 1 - 1e-10)) + (1 - y) * pt.log(pt.clip(1 - p0, 1e-10, 1 - 1e-10))
                loglik0 = loglik0 + pt.log(pt.clip(1 - p_epsilon, 1e-10, 1.0))

                n_quad = 10
                gh_points_np, gh_weights_np = np.polynomial.hermite.hermgauss(n_quad)
                gh_points_scaled = gh_points_np * np.sqrt(2.0)
                gh_weights_norm = gh_weights_np / np.sqrt(np.pi)
                loglik1_components = []
                for i in range(n_quad):
                    eps_val = gh_points_scaled[i] * sigma_eps
                    eta_skew = eta_base + eps_val
                    p1 = inv_link(eta_skew)
                    loglik_i = y * pt.log(pt.clip(p1, 1e-10, 1 - 1e-10)) + (1 - y) * pt.log(pt.clip(1 - p1, 1e-10, 1 - 1e-10))
                    loglik_i = loglik_i + pt.log(gh_weights_norm[i])
                    loglik1_components.append(loglik_i)
                loglik1 = pt.logsumexp(pt.stack(loglik1_components, axis=-1), axis=-1)
                loglik1 = loglik1 + pt.log(pt.clip(p_epsilon, 1e-10, 1.0))
                loglik_total = pt.logsumexp(pt.stack([loglik0, loglik1], axis=-1), axis=-1)
                pm.Potential("y_loglik", pt.sum(loglik_total))
            else:
                z = pm.Bernoulli("z", p=p_epsilon, dims=("person", "item"))
                epsilon = pm.Normal(
                    "epsilon",
                    mu=0.0,
                    sigma=pt.sqrt(1.0 / tau_epsilon),
                    dims=("person", "item")
                )
                eta = eta_base + z * epsilon
                inv_link = get_inverse_link_pt(link, r=r_rv)
                p = inv_link(eta)
                pm.Bernoulli("y", p=p, observed=y, dims=("person", "item"))
        else:
            inv_link = get_inverse_link_pt(link, r=r_rv, xi=xi_rv,
                                          lambda_skew=lambda_skew_rv,
                                          hermite_coeffs=hermite_coeffs_rv,
                                          alpha1=alpha1_rv, alpha2=alpha2_rv)
            p = inv_link(eta_base)
            pm.Bernoulli("y", p=p, observed=y, dims=("person", "item"))
    
    return model, coords


# ============================================================================
# Step Method Construction
# ============================================================================

def _build_step(
    model: pm.Model,
    sampler: SamplerType,
    target_accept: float = 0.9,
    step_kwargs: Optional[dict[str, Any]] = None
) -> pm.step_methods.arraystep.BlockedStep | list:
    sampler_lower = sampler.lower()
    step_kwargs = step_kwargs or {}
    nv = model.named_vars
    steps = []
    
    if sampler_lower in {"nuts", "hmc"}:
        nuts_kwargs = {k: v for k, v in step_kwargs.items() if k != "target_accept"}
        steps.append(pm.NUTS(target_accept=target_accept, **nuts_kwargs))
        
        if "z" in nv:
            steps.append(pm.BinaryGibbsMetropolis(vars=[nv["z"]]))
    
    elif sampler_lower in {"gibbs", "slice"}:
        blocks = []
        
        def add_block(var_names: list[str]):
            block = []
            for name in var_names:
                if name == "mu" and "mu_raw" in nv:
                    continue
                if name in nv and nv[name] in model.free_RVs:
                    block.append(nv[name])
            if block:
                blocks.append(block)
        
        add_block(["loga"])         
        add_block(["b"])            
        add_block(["mu_raw"])       
        add_block(["log_r"])       
        add_block(["epsilon"])      
        add_block(["tau_b", "tau_epsilon", "mu_b"])  
        
        default_widths = {
            0: 1.0,    
            1: 1.0,    
            2: 1.0,    
            3: 0.03,   
            4: 0.25,   
            5: 1.0,    
        }
        
        for i, block in enumerate(blocks):
                width_key = f"w_block_{i}"
                width = step_kwargs.get(width_key, default_widths.get(i, 1.0))
                steps.append(pm.Slice(vars=block, w=width))
        
        if "z" in nv:
            steps.append(pm.BinaryGibbsMetropolis(vars=[nv["z"]]))
    
    elif sampler_lower in {"mh", "metropolis"}:
        cont_vars = []
        var_order = ["loga", "tau_b", "mu_b", "b", "mu_raw", "mu", "tau_epsilon", "log_r", "epsilon"]
        
        for name in var_order:
            if name == "mu" and "mu_raw" in nv:
                continue  
            if name in nv and nv[name] in model.free_RVs:
                cont_vars.append(nv[name])
        
        if cont_vars:
            steps.append(pm.Metropolis(vars=cont_vars, **step_kwargs))

        if "z" in nv:
            steps.append(pm.BinaryGibbsMetropolis(vars=[nv["z"]]))
    
    else:
        raise ValueError(
            f"Unknown sampler '{sampler}'. "
            f"Choose from: nuts, hmc, gibbs, slice, mh, metropolis"
        )
    
    if not steps:
        raise ValueError("No step methods were created")
    
    return steps if len(steps) > 1 else steps[0]


def run_mcmc(
    y: np.ndarray,
    link: LinkType,
    sampler: SamplerType = "nuts",
    draws: int = 1000,
    tune: int = 1000,
    chains: int = 4,
    cores: int = 1,
    target_accept: float = 0.9,
    random_seed: int = 42,
    step_kwargs: Optional[dict[str, Any]] = None,
    progressbar: bool = False,
    silence_output: bool = False,
    **model_kwargs
) -> pm.backends.base.MultiTrace:
    import logging
    import warnings

    model, _ = build_irt_model(y, link, **model_kwargs)

    if silence_output:
        import sys
        import io

        old_pymc_level = logging.getLogger("pymc").level
        old_arviz_level = logging.getLogger("arviz").level
        old_stderr = sys.stderr
        old_stdout = sys.stdout

        logging.getLogger("pymc").setLevel(logging.CRITICAL)
        logging.getLogger("arviz").setLevel(logging.CRITICAL)

        sys.stderr = io.StringIO()
        sys.stdout = io.StringIO()

        with warnings.catch_warnings():
            warnings.simplefilter("ignore")
            with model:
                step = _build_step(model, sampler, target_accept, step_kwargs)
                idata = pm.sample(
                    draws=draws,
                    tune=tune,
                    chains=chains,
                    cores=cores,
                    random_seed=random_seed,
                    step=step,
                    progressbar=progressbar,
                )

        sys.stderr = old_stderr
        sys.stdout = old_stdout
        logging.getLogger("pymc").setLevel(old_pymc_level)
        logging.getLogger("arviz").setLevel(old_arviz_level)
    else:
        with model:
            step = _build_step(model, sampler, target_accept, step_kwargs)
            idata = pm.sample(
                draws=draws,
                tune=tune,
                chains=chains,
                cores=cores,
                random_seed=random_seed,
                step=step,
                progressbar=progressbar,
            )

    return idata


def sample_nuts(
    y: np.ndarray,
    link: LinkType,
    draws: int = 1000,
    tune: int = 1000,
    chains: int = 4,
    cores: int = 1,
    target_accept: float = 0.9,
    random_seed: int = 42,
    **model_kwargs
) -> pm.backends.base.MultiTrace:
    return run_mcmc(
        y, link, sampler="nuts",
        draws=draws, tune=tune, chains=chains, cores=cores,
        target_accept=target_accept, random_seed=random_seed,
        **model_kwargs
    )


def sample_gibbs(
    y: np.ndarray,
    link: LinkType,
    draws: int = 1000,
    tune: int = 1000,
    chains: int = 4,
    cores: int = 1,
    random_seed: int = 42,
    step_kwargs: Optional[dict[str, Any]] = None,
    **model_kwargs
) -> pm.backends.base.MultiTrace:
    
    return run_mcmc(
        y, link, sampler="gibbs",
        draws=draws, tune=tune, chains=chains, cores=cores,
        random_seed=random_seed, step_kwargs=step_kwargs,
        **model_kwargs
    )


def sample_mh(
    y: np.ndarray,
    link: LinkType,
    draws: int = 1000,
    tune: int = 1000,
    chains: int = 4,
    cores: int = 1,
    random_seed: int = 42,
    step_kwargs: Optional[dict[str, Any]] = None,
    **model_kwargs
) -> pm.backends.base.MultiTrace:
    return run_mcmc(
        y, link, sampler="mh",
        draws=draws, tune=tune, chains=chains, cores=cores,
        random_seed=random_seed, step_kwargs=step_kwargs,
        **model_kwargs
    )


def save_mcmc_posterior(
    idata: az.InferenceData,
    save_path: str,
    save_full: bool = False
) -> None:
    if save_full:
        idata.to_netcdf(save_path)
    else:
        posterior_dict = {}
        for var_name in idata.posterior.data_vars:
            posterior_dict[var_name] = idata.posterior[var_name].values

        np.savez_compressed(save_path, **posterior_dict)


if __name__ == "__main__":
    print("=== MCMC Inference Demo ===\n")
    print("This is a minimal example. For full usage, combine with simple_sim.py:")
    print("  from simple_sim_optimized import simulate_data")
    print("  y = simulate_data(N=100, I=20, link='logit', seed=42)")
    print("  idata = run_mcmc(y, link='logit', sampler='nuts', draws=500)")
    print("  print(idata.posterior)")

